{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Performing Machine Learning Analysis on 2ndphase information and Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the necessary packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining Output from 1st Phase Analysis to Data from 2nd Phase Analysis**<br>\n",
    "In this stage, wewill combine the information gained from the principle component analysis which was obtained as output of phase 1 of our model with the feature selected features from our challenge dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SUBJECT        PC1       PC2    RID   AGE  GENDER  EDUCATION  \\\n",
      "0    002_S_0295   2.370924 -0.693114  295.0  84.8    Male       18.0   \n",
      "1    002_S_0295   2.372282 -1.203138  295.0  84.8    Male       18.0   \n",
      "2    002_S_0295   2.372031 -0.698526  295.0  84.8    Male       18.0   \n",
      "3    002_S_0295   2.407100 -0.976808  295.0  84.8    Male       18.0   \n",
      "4    002_S_0413   1.672813 -0.126494  413.0  76.3  Female       16.0   \n",
      "5    002_S_0413   1.236724  0.096254  413.0  76.3  Female       16.0   \n",
      "6    002_S_0413   1.671244 -0.111068  413.0  76.3  Female       16.0   \n",
      "7    002_S_0413   1.566481  0.003706  413.0  76.3  Female       16.0   \n",
      "8    002_S_0619  12.930872  3.287687  619.0  77.5    Male       12.0   \n",
      "9    002_S_0619  11.014633  2.667719  619.0  77.5    Male       12.0   \n",
      "10   002_S_0619  13.146209  3.300931  619.0  77.5    Male       12.0   \n",
      "11   002_S_0619   3.274378  0.367081  619.0  77.5    Male       12.0   \n",
      "12   002_S_0619  12.479669  3.292650  619.0  77.5    Male       12.0   \n",
      "13   002_S_0685   1.396280 -0.275740  685.0  89.6  Female       16.0   \n",
      "14   002_S_0685   1.947561 -0.682646  685.0  89.6  Female       16.0   \n",
      "15   002_S_0685   1.057695 -0.044045  685.0  89.6  Female       16.0   \n",
      "16   002_S_0685   0.719146 -1.622577  685.0  89.6  Female       16.0   \n",
      "17   002_S_0685   1.939947 -0.667425  685.0  89.6  Female       16.0   \n",
      "18   002_S_0729   1.220856 -0.591295  729.0  65.1  Female       16.0   \n",
      "19   002_S_0729   1.512613 -0.445216  729.0  65.1  Female       16.0   \n",
      "20   002_S_0729   2.120150 -0.425385  729.0  65.1  Female       16.0   \n",
      "21   002_S_0729   1.654829 -0.211349  729.0  65.1  Female       16.0   \n",
      "22   002_S_0729   1.486072 -0.593188  729.0  65.1  Female       16.0   \n",
      "23   002_S_0729   1.509587 -0.457521  729.0  65.1  Female       16.0   \n",
      "24   002_S_0782   1.397825 -0.377399  782.0  81.6    Male       16.0   \n",
      "25   002_S_0782   1.161550  0.073611  782.0  81.6    Male       16.0   \n",
      "26   002_S_0782   1.116192 -0.052470  782.0  81.6    Male       16.0   \n",
      "27   002_S_0782   1.329539 -0.019937  782.0  81.6    Male       16.0   \n",
      "28   002_S_0782   0.943902 -0.042377  782.0  81.6    Male       16.0   \n",
      "29   002_S_0782   1.138651  0.111009  782.0  81.6    Male       16.0   \n",
      "..          ...        ...       ...    ...   ...     ...        ...   \n",
      "671  023_S_0376  -1.058529 -0.724079  376.0  70.5    Male       15.0   \n",
      "672  023_S_0388  -0.795688  0.891054  388.0  71.2    Male       15.0   \n",
      "673  023_S_0388  -0.795754  0.892515  388.0  71.2    Male       15.0   \n",
      "674  023_S_0388  -0.691891  1.498761  388.0  71.2    Male       15.0   \n",
      "675  023_S_0388  -0.730331  1.255325  388.0  71.2    Male       15.0   \n",
      "676  023_S_0388  -0.847385 -0.527001  388.0  71.2    Male       15.0   \n",
      "677  023_S_0388  -0.724312  0.504045  388.0  71.2    Male       15.0   \n",
      "678  023_S_0388  -0.692056  1.502962  388.0  71.2    Male       15.0   \n",
      "679  023_S_0388  -0.730134  1.258852  388.0  71.2    Male       15.0   \n",
      "680  023_S_0604  -1.006046 -0.116208  604.0  86.5    Male       14.0   \n",
      "681  023_S_0604  -1.006013 -0.117241  604.0  86.5    Male       14.0   \n",
      "682  023_S_0604  -0.964143  0.019548  604.0  86.5    Male       14.0   \n",
      "683  023_S_0604  -0.962141 -1.013755  604.0  86.5    Male       14.0   \n",
      "684  023_S_0604  -0.969331 -1.385252  604.0  86.5    Male       14.0   \n",
      "685  023_S_0604  -0.909845 -1.515485  604.0  86.5    Male       14.0   \n",
      "686  023_S_0604  -0.964601  0.020774  604.0  86.5    Male       14.0   \n",
      "687  023_S_0604  -0.962577 -1.013291  604.0  86.5    Male       14.0   \n",
      "688  023_S_0625  -0.965031 -1.866164  625.0  75.9    Male        6.0   \n",
      "689  023_S_0625  -0.918598 -1.718849  625.0  75.9    Male        6.0   \n",
      "690  023_S_0625  -0.953879 -2.317932  625.0  75.9    Male        6.0   \n",
      "691  023_S_0625  -0.929734 -2.453419  625.0  75.9    Male        6.0   \n",
      "692  023_S_0625  -0.965734 -1.853002  625.0  75.9    Male        6.0   \n",
      "693  023_S_0625  -0.900235 -3.088168  625.0  75.9    Male        6.0   \n",
      "694  023_S_0887  -0.501578  1.488959  887.0  73.7  Female        8.0   \n",
      "695  023_S_0887  -0.567190  1.084834  887.0  73.7  Female        8.0   \n",
      "696  023_S_0887  -0.659152  0.072797  887.0  73.7  Female        8.0   \n",
      "697  023_S_0887  -0.674929 -0.121147  887.0  73.7  Female        8.0   \n",
      "698  023_S_0887  -0.684335 -0.123274  887.0  73.7  Female        8.0   \n",
      "699  023_S_0887  -0.501504  1.490115  887.0  73.7  Female        8.0   \n",
      "700  023_S_0887  -0.567368  1.085522  887.0  73.7  Female        8.0   \n",
      "\n",
      "           ETHNICITY   RACE  APOE4  MMSE STATUS  \n",
      "0    Not Hisp/Latino  White    1.0  28.0     CN  \n",
      "1    Not Hisp/Latino  White    1.0  28.0     CN  \n",
      "2    Not Hisp/Latino  White    1.0  28.0     CN  \n",
      "3    Not Hisp/Latino  White    1.0  28.0     CN  \n",
      "4    Not Hisp/Latino  White    0.0  29.0     CN  \n",
      "5    Not Hisp/Latino  White    0.0  29.0     CN  \n",
      "6    Not Hisp/Latino  White    0.0  29.0     CN  \n",
      "7    Not Hisp/Latino  White    0.0  29.0     CN  \n",
      "8    Not Hisp/Latino  White    2.0  22.0     AD  \n",
      "9    Not Hisp/Latino  White    2.0  22.0     AD  \n",
      "10   Not Hisp/Latino  White    2.0  22.0     AD  \n",
      "11   Not Hisp/Latino  White    2.0  22.0     AD  \n",
      "12   Not Hisp/Latino  White    2.0  22.0     AD  \n",
      "13   Not Hisp/Latino  White    0.0  30.0     CN  \n",
      "14   Not Hisp/Latino  White    0.0  30.0     CN  \n",
      "15   Not Hisp/Latino  White    0.0  30.0     CN  \n",
      "16   Not Hisp/Latino  White    0.0  30.0     CN  \n",
      "17   Not Hisp/Latino  White    0.0  30.0     CN  \n",
      "18   Not Hisp/Latino  White    1.0  27.0   LMCI  \n",
      "19   Not Hisp/Latino  White    1.0  27.0   LMCI  \n",
      "20   Not Hisp/Latino  White    1.0  27.0   LMCI  \n",
      "21   Not Hisp/Latino  White    1.0  27.0   LMCI  \n",
      "22   Not Hisp/Latino  White    1.0  27.0   LMCI  \n",
      "23   Not Hisp/Latino  White    1.0  27.0   LMCI  \n",
      "24   Not Hisp/Latino  White    0.0  29.0   LMCI  \n",
      "25   Not Hisp/Latino  White    0.0  29.0   LMCI  \n",
      "26   Not Hisp/Latino  White    0.0  29.0   LMCI  \n",
      "27   Not Hisp/Latino  White    0.0  29.0   LMCI  \n",
      "28   Not Hisp/Latino  White    0.0  29.0   LMCI  \n",
      "29   Not Hisp/Latino  White    0.0  29.0   LMCI  \n",
      "..               ...    ...    ...   ...    ...  \n",
      "671  Not Hisp/Latino  White    0.0  28.0   LMCI  \n",
      "672  Not Hisp/Latino  White    2.0  25.0   LMCI  \n",
      "673  Not Hisp/Latino  White    2.0  25.0   LMCI  \n",
      "674  Not Hisp/Latino  White    2.0  25.0   LMCI  \n",
      "675  Not Hisp/Latino  White    2.0  25.0   LMCI  \n",
      "676  Not Hisp/Latino  White    2.0  25.0   LMCI  \n",
      "677  Not Hisp/Latino  White    2.0  25.0   LMCI  \n",
      "678  Not Hisp/Latino  White    2.0  25.0   LMCI  \n",
      "679  Not Hisp/Latino  White    2.0  25.0   LMCI  \n",
      "680  Not Hisp/Latino  White    0.0  25.0   LMCI  \n",
      "681  Not Hisp/Latino  White    0.0  25.0   LMCI  \n",
      "682  Not Hisp/Latino  White    0.0  25.0   LMCI  \n",
      "683  Not Hisp/Latino  White    0.0  25.0   LMCI  \n",
      "684  Not Hisp/Latino  White    0.0  25.0   LMCI  \n",
      "685  Not Hisp/Latino  White    0.0  25.0   LMCI  \n",
      "686  Not Hisp/Latino  White    0.0  25.0   LMCI  \n",
      "687  Not Hisp/Latino  White    0.0  25.0   LMCI  \n",
      "688  Not Hisp/Latino  White    0.0  24.0   LMCI  \n",
      "689  Not Hisp/Latino  White    0.0  24.0   LMCI  \n",
      "690  Not Hisp/Latino  White    0.0  24.0   LMCI  \n",
      "691  Not Hisp/Latino  White    0.0  24.0   LMCI  \n",
      "692  Not Hisp/Latino  White    0.0  24.0   LMCI  \n",
      "693  Not Hisp/Latino  White    0.0  24.0   LMCI  \n",
      "694  Not Hisp/Latino  White    1.0  24.0   LMCI  \n",
      "695  Not Hisp/Latino  White    1.0  24.0   LMCI  \n",
      "696  Not Hisp/Latino  White    1.0  24.0   LMCI  \n",
      "697  Not Hisp/Latino  White    1.0  24.0   LMCI  \n",
      "698  Not Hisp/Latino  White    1.0  24.0   LMCI  \n",
      "699  Not Hisp/Latino  White    1.0  24.0   LMCI  \n",
      "700  Not Hisp/Latino  White    1.0  24.0   LMCI  \n",
      "\n",
      "[701 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('1st Phase Output.csv')\n",
    "df1=pd.read_csv('DB_Phase2.csv')\n",
    "subject=df['Subject_ID']\n",
    "df=df.dropna()\n",
    "df=df.reset_index(drop=True)\n",
    "df1=df1.drop(['Subject_ID'],axis=1)\n",
    "\n",
    "df_phase_2=pd.concat([df,df1],axis=1)\n",
    "df_phase_2=df_phase_2.values.tolist()\n",
    "header=[\"SUBJECT\",\"PC1\",\"PC2\",\"RID\", \"AGE\", \"GENDER\", \"EDUCATION\",\"ETHNICITY\",\"RACE\",\"APOE4\",\"MMSE\",\"STATUS\"]\n",
    "csvdata=header\n",
    "with open(\"ML.csv\",\"w\",encoding='utf-8') as csvFile:\n",
    "    writer=csv.writer(csvFile)\n",
    "    writer.writerow(csvdata)\n",
    "csvFile.close()\n",
    "\n",
    "csvdata=df_phase_2\n",
    "with open(\"ML.csv\",\"a\",encoding='utf-8') as csvFile:\n",
    "    writer=csv.writer(csvFile)\n",
    "    writer.writerows(csvdata)\n",
    "csvFile.close()\n",
    "\n",
    "data=pd.read_csv('ML.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing Data for Initial ML Analysis**<br>\n",
    "In most Machine Learning functions offered by Scikit Learn, the functions are not capable of being able to read Categorical data. From our created dataset. Many factors like Gender, Subject_ID, Ethnicity, Race and so on present categorical values. Hence, we have performed One Hot Encoding to binary discretize Categorical columns, and we have usedLabel Encoder to Label the Target Status \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           PC1       PC2    RID   AGE  EDUCATION  APOE4  MMSE  002_S_0295  \\\n",
      "0     2.370924 -0.693114  295.0  84.8       18.0    1.0  28.0           1   \n",
      "1     2.372282 -1.203138  295.0  84.8       18.0    1.0  28.0           1   \n",
      "2     2.372031 -0.698526  295.0  84.8       18.0    1.0  28.0           1   \n",
      "3     2.407100 -0.976808  295.0  84.8       18.0    1.0  28.0           1   \n",
      "4     1.672813 -0.126494  413.0  76.3       16.0    0.0  29.0           0   \n",
      "5     1.236724  0.096254  413.0  76.3       16.0    0.0  29.0           0   \n",
      "6     1.671244 -0.111068  413.0  76.3       16.0    0.0  29.0           0   \n",
      "7     1.566481  0.003706  413.0  76.3       16.0    0.0  29.0           0   \n",
      "8    12.930872  3.287687  619.0  77.5       12.0    2.0  22.0           0   \n",
      "9    11.014633  2.667719  619.0  77.5       12.0    2.0  22.0           0   \n",
      "10   13.146209  3.300931  619.0  77.5       12.0    2.0  22.0           0   \n",
      "11    3.274378  0.367081  619.0  77.5       12.0    2.0  22.0           0   \n",
      "12   12.479669  3.292650  619.0  77.5       12.0    2.0  22.0           0   \n",
      "13    1.396280 -0.275740  685.0  89.6       16.0    0.0  30.0           0   \n",
      "14    1.947561 -0.682646  685.0  89.6       16.0    0.0  30.0           0   \n",
      "15    1.057695 -0.044045  685.0  89.6       16.0    0.0  30.0           0   \n",
      "16    0.719146 -1.622577  685.0  89.6       16.0    0.0  30.0           0   \n",
      "17    1.939947 -0.667425  685.0  89.6       16.0    0.0  30.0           0   \n",
      "18    1.220856 -0.591295  729.0  65.1       16.0    1.0  27.0           0   \n",
      "19    1.512613 -0.445216  729.0  65.1       16.0    1.0  27.0           0   \n",
      "20    2.120150 -0.425385  729.0  65.1       16.0    1.0  27.0           0   \n",
      "21    1.654829 -0.211349  729.0  65.1       16.0    1.0  27.0           0   \n",
      "22    1.486072 -0.593188  729.0  65.1       16.0    1.0  27.0           0   \n",
      "23    1.509587 -0.457521  729.0  65.1       16.0    1.0  27.0           0   \n",
      "24    1.397825 -0.377399  782.0  81.6       16.0    0.0  29.0           0   \n",
      "25    1.161550  0.073611  782.0  81.6       16.0    0.0  29.0           0   \n",
      "26    1.116192 -0.052470  782.0  81.6       16.0    0.0  29.0           0   \n",
      "27    1.329539 -0.019937  782.0  81.6       16.0    0.0  29.0           0   \n",
      "28    0.943902 -0.042377  782.0  81.6       16.0    0.0  29.0           0   \n",
      "29    1.138651  0.111009  782.0  81.6       16.0    0.0  29.0           0   \n",
      "..         ...       ...    ...   ...        ...    ...   ...         ...   \n",
      "671  -1.058529 -0.724079  376.0  70.5       15.0    0.0  28.0           0   \n",
      "672  -0.795688  0.891054  388.0  71.2       15.0    2.0  25.0           0   \n",
      "673  -0.795754  0.892515  388.0  71.2       15.0    2.0  25.0           0   \n",
      "674  -0.691891  1.498761  388.0  71.2       15.0    2.0  25.0           0   \n",
      "675  -0.730331  1.255325  388.0  71.2       15.0    2.0  25.0           0   \n",
      "676  -0.847385 -0.527001  388.0  71.2       15.0    2.0  25.0           0   \n",
      "677  -0.724312  0.504045  388.0  71.2       15.0    2.0  25.0           0   \n",
      "678  -0.692056  1.502962  388.0  71.2       15.0    2.0  25.0           0   \n",
      "679  -0.730134  1.258852  388.0  71.2       15.0    2.0  25.0           0   \n",
      "680  -1.006046 -0.116208  604.0  86.5       14.0    0.0  25.0           0   \n",
      "681  -1.006013 -0.117241  604.0  86.5       14.0    0.0  25.0           0   \n",
      "682  -0.964143  0.019548  604.0  86.5       14.0    0.0  25.0           0   \n",
      "683  -0.962141 -1.013755  604.0  86.5       14.0    0.0  25.0           0   \n",
      "684  -0.969331 -1.385252  604.0  86.5       14.0    0.0  25.0           0   \n",
      "685  -0.909845 -1.515485  604.0  86.5       14.0    0.0  25.0           0   \n",
      "686  -0.964601  0.020774  604.0  86.5       14.0    0.0  25.0           0   \n",
      "687  -0.962577 -1.013291  604.0  86.5       14.0    0.0  25.0           0   \n",
      "688  -0.965031 -1.866164  625.0  75.9        6.0    0.0  24.0           0   \n",
      "689  -0.918598 -1.718849  625.0  75.9        6.0    0.0  24.0           0   \n",
      "690  -0.953879 -2.317932  625.0  75.9        6.0    0.0  24.0           0   \n",
      "691  -0.929734 -2.453419  625.0  75.9        6.0    0.0  24.0           0   \n",
      "692  -0.965734 -1.853002  625.0  75.9        6.0    0.0  24.0           0   \n",
      "693  -0.900235 -3.088168  625.0  75.9        6.0    0.0  24.0           0   \n",
      "694  -0.501578  1.488959  887.0  73.7        8.0    1.0  24.0           0   \n",
      "695  -0.567190  1.084834  887.0  73.7        8.0    1.0  24.0           0   \n",
      "696  -0.659152  0.072797  887.0  73.7        8.0    1.0  24.0           0   \n",
      "697  -0.674929 -0.121147  887.0  73.7        8.0    1.0  24.0           0   \n",
      "698  -0.684335 -0.123274  887.0  73.7        8.0    1.0  24.0           0   \n",
      "699  -0.501504  1.490115  887.0  73.7        8.0    1.0  24.0           0   \n",
      "700  -0.567368  1.085522  887.0  73.7        8.0    1.0  24.0           0   \n",
      "\n",
      "     002_S_0413  002_S_0619  ...  023_S_0388  023_S_0604  023_S_0625  \\\n",
      "0             0           0  ...           0           0           0   \n",
      "1             0           0  ...           0           0           0   \n",
      "2             0           0  ...           0           0           0   \n",
      "3             0           0  ...           0           0           0   \n",
      "4             1           0  ...           0           0           0   \n",
      "5             1           0  ...           0           0           0   \n",
      "6             1           0  ...           0           0           0   \n",
      "7             1           0  ...           0           0           0   \n",
      "8             0           1  ...           0           0           0   \n",
      "9             0           1  ...           0           0           0   \n",
      "10            0           1  ...           0           0           0   \n",
      "11            0           1  ...           0           0           0   \n",
      "12            0           1  ...           0           0           0   \n",
      "13            0           0  ...           0           0           0   \n",
      "14            0           0  ...           0           0           0   \n",
      "15            0           0  ...           0           0           0   \n",
      "16            0           0  ...           0           0           0   \n",
      "17            0           0  ...           0           0           0   \n",
      "18            0           0  ...           0           0           0   \n",
      "19            0           0  ...           0           0           0   \n",
      "20            0           0  ...           0           0           0   \n",
      "21            0           0  ...           0           0           0   \n",
      "22            0           0  ...           0           0           0   \n",
      "23            0           0  ...           0           0           0   \n",
      "24            0           0  ...           0           0           0   \n",
      "25            0           0  ...           0           0           0   \n",
      "26            0           0  ...           0           0           0   \n",
      "27            0           0  ...           0           0           0   \n",
      "28            0           0  ...           0           0           0   \n",
      "29            0           0  ...           0           0           0   \n",
      "..          ...         ...  ...         ...         ...         ...   \n",
      "671           0           0  ...           0           0           0   \n",
      "672           0           0  ...           1           0           0   \n",
      "673           0           0  ...           1           0           0   \n",
      "674           0           0  ...           1           0           0   \n",
      "675           0           0  ...           1           0           0   \n",
      "676           0           0  ...           1           0           0   \n",
      "677           0           0  ...           1           0           0   \n",
      "678           0           0  ...           1           0           0   \n",
      "679           0           0  ...           1           0           0   \n",
      "680           0           0  ...           0           1           0   \n",
      "681           0           0  ...           0           1           0   \n",
      "682           0           0  ...           0           1           0   \n",
      "683           0           0  ...           0           1           0   \n",
      "684           0           0  ...           0           1           0   \n",
      "685           0           0  ...           0           1           0   \n",
      "686           0           0  ...           0           1           0   \n",
      "687           0           0  ...           0           1           0   \n",
      "688           0           0  ...           0           0           1   \n",
      "689           0           0  ...           0           0           1   \n",
      "690           0           0  ...           0           0           1   \n",
      "691           0           0  ...           0           0           1   \n",
      "692           0           0  ...           0           0           1   \n",
      "693           0           0  ...           0           0           1   \n",
      "694           0           0  ...           0           0           0   \n",
      "695           0           0  ...           0           0           0   \n",
      "696           0           0  ...           0           0           0   \n",
      "697           0           0  ...           0           0           0   \n",
      "698           0           0  ...           0           0           0   \n",
      "699           0           0  ...           0           0           0   \n",
      "700           0           0  ...           0           0           0   \n",
      "\n",
      "     023_S_0887  Female  Male  Hisp/Latino  Not Hisp/Latino  Black  White  \n",
      "0             0       0     1            0                1      0      1  \n",
      "1             0       0     1            0                1      0      1  \n",
      "2             0       0     1            0                1      0      1  \n",
      "3             0       0     1            0                1      0      1  \n",
      "4             0       1     0            0                1      0      1  \n",
      "5             0       1     0            0                1      0      1  \n",
      "6             0       1     0            0                1      0      1  \n",
      "7             0       1     0            0                1      0      1  \n",
      "8             0       0     1            0                1      0      1  \n",
      "9             0       0     1            0                1      0      1  \n",
      "10            0       0     1            0                1      0      1  \n",
      "11            0       0     1            0                1      0      1  \n",
      "12            0       0     1            0                1      0      1  \n",
      "13            0       1     0            0                1      0      1  \n",
      "14            0       1     0            0                1      0      1  \n",
      "15            0       1     0            0                1      0      1  \n",
      "16            0       1     0            0                1      0      1  \n",
      "17            0       1     0            0                1      0      1  \n",
      "18            0       1     0            0                1      0      1  \n",
      "19            0       1     0            0                1      0      1  \n",
      "20            0       1     0            0                1      0      1  \n",
      "21            0       1     0            0                1      0      1  \n",
      "22            0       1     0            0                1      0      1  \n",
      "23            0       1     0            0                1      0      1  \n",
      "24            0       0     1            0                1      0      1  \n",
      "25            0       0     1            0                1      0      1  \n",
      "26            0       0     1            0                1      0      1  \n",
      "27            0       0     1            0                1      0      1  \n",
      "28            0       0     1            0                1      0      1  \n",
      "29            0       0     1            0                1      0      1  \n",
      "..          ...     ...   ...          ...              ...    ...    ...  \n",
      "671           0       0     1            0                1      0      1  \n",
      "672           0       0     1            0                1      0      1  \n",
      "673           0       0     1            0                1      0      1  \n",
      "674           0       0     1            0                1      0      1  \n",
      "675           0       0     1            0                1      0      1  \n",
      "676           0       0     1            0                1      0      1  \n",
      "677           0       0     1            0                1      0      1  \n",
      "678           0       0     1            0                1      0      1  \n",
      "679           0       0     1            0                1      0      1  \n",
      "680           0       0     1            0                1      0      1  \n",
      "681           0       0     1            0                1      0      1  \n",
      "682           0       0     1            0                1      0      1  \n",
      "683           0       0     1            0                1      0      1  \n",
      "684           0       0     1            0                1      0      1  \n",
      "685           0       0     1            0                1      0      1  \n",
      "686           0       0     1            0                1      0      1  \n",
      "687           0       0     1            0                1      0      1  \n",
      "688           0       0     1            0                1      0      1  \n",
      "689           0       0     1            0                1      0      1  \n",
      "690           0       0     1            0                1      0      1  \n",
      "691           0       0     1            0                1      0      1  \n",
      "692           0       0     1            0                1      0      1  \n",
      "693           0       0     1            0                1      0      1  \n",
      "694           1       1     0            0                1      0      1  \n",
      "695           1       1     0            0                1      0      1  \n",
      "696           1       1     0            0                1      0      1  \n",
      "697           1       1     0            0                1      0      1  \n",
      "698           1       1     0            0                1      0      1  \n",
      "699           1       1     0            0                1      0      1  \n",
      "700           1       1     0            0                1      0      1  \n",
      "\n",
      "[697 rows x 162 columns]\n",
      "[1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2\n",
      " 2 2 2 2 2 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2\n",
      " 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 2 2 2 0 0\n",
      " 1 1 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 0\n",
      " 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 0 0 0 2 2\n",
      " 2 2 2 0 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2\n",
      " 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1\n",
      " 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 0 0 0 0 2 2 2 2 2 2 2 2 2 2 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 1 1 0 0 0 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 0 0 2 2 2 2 2 2 2 2 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "data=data.dropna()\n",
    "data2=data\n",
    "data2=data2.drop(['GENDER'],axis=1)\n",
    "data2=data2.drop(['SUBJECT'],axis=1)\n",
    "data2=data2.drop(['ETHNICITY'],axis=1)\n",
    "data2=data2.drop(['RACE'],axis=1)\n",
    "dummies=pd.get_dummies(data.SUBJECT)\n",
    "dummies2=pd.get_dummies(data.GENDER)\n",
    "dummies3=pd.get_dummies(data.ETHNICITY)\n",
    "dummies4=pd.get_dummies(data.RACE)\n",
    "data2=pd.concat([data2,dummies],axis=1)\n",
    "data2=pd.concat([data2,dummies2],axis=1)\n",
    "data2=pd.concat([data2,dummies3],axis=1)\n",
    "data2=pd.concat([data2,dummies4],axis=1)\n",
    "\n",
    "le=LabelEncoder()\n",
    "Y=le.fit_transform(data2.STATUS.astype(str))\n",
    "X=data2.drop(['STATUS'],axis=1)\n",
    "print(X)\n",
    "print(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classification**<br>\n",
    "In this stage, we will divide the Dataset into training and test data. We will then apply the Random Forest Classifier to the training input and targets. We will look at the efficiency of the algorithm on the Training data. Then we will use the algorithm to predict test data output to know the efficiency of our algoritm after which we will evaluate the model and obtain Mean Avg precision, recall and f1 scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of a Random Forest is: 97.3\n",
      "Accuracy of a Random Forest predicted over actual is: 97.86\n",
      "The confusion Matrix is as Below:\n",
      "\n",
      "[[18  0  1]\n",
      " [ 0 41  2]\n",
      " [ 0  0 78]]\n",
      "\n",
      "The Evaluation Report is as Below:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       1.00      0.95      0.97        19\n",
      "          CN       1.00      0.95      0.98        43\n",
      "        LMCI       0.96      1.00      0.98        78\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       140\n",
      "   macro avg       0.99      0.97      0.98       140\n",
      "weighted avg       0.98      0.98      0.98       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2)\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf=clf.fit(x_train,y_train)\n",
    "\n",
    "scores = cross_val_score(clf, x_train, y_train, cv=5)\n",
    "print(\"Accuracy of a Random Forest is:\",round(np.mean((scores*100)),2))\n",
    "\n",
    "yp=clf.predict(x_test)\n",
    "print(\"Accuracy of a Random Forest predicted over actual is:\",round(((accuracy_score(y_test,yp))*100),2))\n",
    "listt=list(le.classes_)\n",
    "y_test=list(le.inverse_transform(y_test))\n",
    "yp=list(le.inverse_transform(yp))\n",
    "#Evaluation\n",
    "print('The confusion Matrix is as Below:\\n')\n",
    "print(confusion_matrix(y_test,yp,labels=listt))\n",
    "print('\\nThe Evaluation Report is as Below:\\n')\n",
    "print(classification_report(y_test,yp,target_names=listt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probabilistic Distillation**<br>\n",
    "The Output acquired on the test data in the previous phase is then divided probabilistically to denote, what % of the test data, pertains to a particular status value of the output(CN, AD, lMCI). \n",
    "Then these probabilities are binned or rounded off to the nearest 1 point decimal value and the entire probabilistic values are added to the Input of the dataset to create a new dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           PC1       PC2    RID   AGE  EDUCATION  APOE4  MMSE  002_S_0295  \\\n",
      "0     2.370924 -0.693114  295.0  84.8       18.0    1.0  28.0           1   \n",
      "1     2.372282 -1.203138  295.0  84.8       18.0    1.0  28.0           1   \n",
      "2     2.372031 -0.698526  295.0  84.8       18.0    1.0  28.0           1   \n",
      "3     2.407100 -0.976808  295.0  84.8       18.0    1.0  28.0           1   \n",
      "4     1.672813 -0.126494  413.0  76.3       16.0    0.0  29.0           0   \n",
      "5     1.236724  0.096254  413.0  76.3       16.0    0.0  29.0           0   \n",
      "6     1.671244 -0.111068  413.0  76.3       16.0    0.0  29.0           0   \n",
      "7     1.566481  0.003706  413.0  76.3       16.0    0.0  29.0           0   \n",
      "8    12.930872  3.287687  619.0  77.5       12.0    2.0  22.0           0   \n",
      "9    11.014633  2.667719  619.0  77.5       12.0    2.0  22.0           0   \n",
      "10   13.146209  3.300931  619.0  77.5       12.0    2.0  22.0           0   \n",
      "11    3.274378  0.367081  619.0  77.5       12.0    2.0  22.0           0   \n",
      "12   12.479669  3.292650  619.0  77.5       12.0    2.0  22.0           0   \n",
      "13    1.396280 -0.275740  685.0  89.6       16.0    0.0  30.0           0   \n",
      "14    1.947561 -0.682646  685.0  89.6       16.0    0.0  30.0           0   \n",
      "15    1.057695 -0.044045  685.0  89.6       16.0    0.0  30.0           0   \n",
      "16    0.719146 -1.622577  685.0  89.6       16.0    0.0  30.0           0   \n",
      "17    1.939947 -0.667425  685.0  89.6       16.0    0.0  30.0           0   \n",
      "18    1.220856 -0.591295  729.0  65.1       16.0    1.0  27.0           0   \n",
      "19    1.512613 -0.445216  729.0  65.1       16.0    1.0  27.0           0   \n",
      "20    2.120150 -0.425385  729.0  65.1       16.0    1.0  27.0           0   \n",
      "21    1.654829 -0.211349  729.0  65.1       16.0    1.0  27.0           0   \n",
      "22    1.486072 -0.593188  729.0  65.1       16.0    1.0  27.0           0   \n",
      "23    1.509587 -0.457521  729.0  65.1       16.0    1.0  27.0           0   \n",
      "24    1.397825 -0.377399  782.0  81.6       16.0    0.0  29.0           0   \n",
      "25    1.161550  0.073611  782.0  81.6       16.0    0.0  29.0           0   \n",
      "26    1.116192 -0.052470  782.0  81.6       16.0    0.0  29.0           0   \n",
      "27    1.329539 -0.019937  782.0  81.6       16.0    0.0  29.0           0   \n",
      "28    0.943902 -0.042377  782.0  81.6       16.0    0.0  29.0           0   \n",
      "29    1.138651  0.111009  782.0  81.6       16.0    0.0  29.0           0   \n",
      "..         ...       ...    ...   ...        ...    ...   ...         ...   \n",
      "671  -1.058529 -0.724079  376.0  70.5       15.0    0.0  28.0           0   \n",
      "672  -0.795688  0.891054  388.0  71.2       15.0    2.0  25.0           0   \n",
      "673  -0.795754  0.892515  388.0  71.2       15.0    2.0  25.0           0   \n",
      "674  -0.691891  1.498761  388.0  71.2       15.0    2.0  25.0           0   \n",
      "675  -0.730331  1.255325  388.0  71.2       15.0    2.0  25.0           0   \n",
      "676  -0.847385 -0.527001  388.0  71.2       15.0    2.0  25.0           0   \n",
      "677  -0.724312  0.504045  388.0  71.2       15.0    2.0  25.0           0   \n",
      "678  -0.692056  1.502962  388.0  71.2       15.0    2.0  25.0           0   \n",
      "679  -0.730134  1.258852  388.0  71.2       15.0    2.0  25.0           0   \n",
      "680  -1.006046 -0.116208  604.0  86.5       14.0    0.0  25.0           0   \n",
      "681  -1.006013 -0.117241  604.0  86.5       14.0    0.0  25.0           0   \n",
      "682  -0.964143  0.019548  604.0  86.5       14.0    0.0  25.0           0   \n",
      "683  -0.962141 -1.013755  604.0  86.5       14.0    0.0  25.0           0   \n",
      "684  -0.969331 -1.385252  604.0  86.5       14.0    0.0  25.0           0   \n",
      "685  -0.909845 -1.515485  604.0  86.5       14.0    0.0  25.0           0   \n",
      "686  -0.964601  0.020774  604.0  86.5       14.0    0.0  25.0           0   \n",
      "687  -0.962577 -1.013291  604.0  86.5       14.0    0.0  25.0           0   \n",
      "688  -0.965031 -1.866164  625.0  75.9        6.0    0.0  24.0           0   \n",
      "689  -0.918598 -1.718849  625.0  75.9        6.0    0.0  24.0           0   \n",
      "690  -0.953879 -2.317932  625.0  75.9        6.0    0.0  24.0           0   \n",
      "691  -0.929734 -2.453419  625.0  75.9        6.0    0.0  24.0           0   \n",
      "692  -0.965734 -1.853002  625.0  75.9        6.0    0.0  24.0           0   \n",
      "693  -0.900235 -3.088168  625.0  75.9        6.0    0.0  24.0           0   \n",
      "694  -0.501578  1.488959  887.0  73.7        8.0    1.0  24.0           0   \n",
      "695  -0.567190  1.084834  887.0  73.7        8.0    1.0  24.0           0   \n",
      "696  -0.659152  0.072797  887.0  73.7        8.0    1.0  24.0           0   \n",
      "697  -0.674929 -0.121147  887.0  73.7        8.0    1.0  24.0           0   \n",
      "698  -0.684335 -0.123274  887.0  73.7        8.0    1.0  24.0           0   \n",
      "699  -0.501504  1.490115  887.0  73.7        8.0    1.0  24.0           0   \n",
      "700  -0.567368  1.085522  887.0  73.7        8.0    1.0  24.0           0   \n",
      "\n",
      "     002_S_0413  002_S_0619  ...  023_S_0887  Female  Male  Hisp/Latino  \\\n",
      "0             0           0  ...           0       0     1            0   \n",
      "1             0           0  ...           0       0     1            0   \n",
      "2             0           0  ...           0       0     1            0   \n",
      "3             0           0  ...           0       0     1            0   \n",
      "4             1           0  ...           0       1     0            0   \n",
      "5             1           0  ...           0       1     0            0   \n",
      "6             1           0  ...           0       1     0            0   \n",
      "7             1           0  ...           0       1     0            0   \n",
      "8             0           1  ...           0       0     1            0   \n",
      "9             0           1  ...           0       0     1            0   \n",
      "10            0           1  ...           0       0     1            0   \n",
      "11            0           1  ...           0       0     1            0   \n",
      "12            0           1  ...           0       0     1            0   \n",
      "13            0           0  ...           0       1     0            0   \n",
      "14            0           0  ...           0       1     0            0   \n",
      "15            0           0  ...           0       1     0            0   \n",
      "16            0           0  ...           0       1     0            0   \n",
      "17            0           0  ...           0       1     0            0   \n",
      "18            0           0  ...           0       1     0            0   \n",
      "19            0           0  ...           0       1     0            0   \n",
      "20            0           0  ...           0       1     0            0   \n",
      "21            0           0  ...           0       1     0            0   \n",
      "22            0           0  ...           0       1     0            0   \n",
      "23            0           0  ...           0       1     0            0   \n",
      "24            0           0  ...           0       0     1            0   \n",
      "25            0           0  ...           0       0     1            0   \n",
      "26            0           0  ...           0       0     1            0   \n",
      "27            0           0  ...           0       0     1            0   \n",
      "28            0           0  ...           0       0     1            0   \n",
      "29            0           0  ...           0       0     1            0   \n",
      "..          ...         ...  ...         ...     ...   ...          ...   \n",
      "671           0           0  ...           0       0     1            0   \n",
      "672           0           0  ...           0       0     1            0   \n",
      "673           0           0  ...           0       0     1            0   \n",
      "674           0           0  ...           0       0     1            0   \n",
      "675           0           0  ...           0       0     1            0   \n",
      "676           0           0  ...           0       0     1            0   \n",
      "677           0           0  ...           0       0     1            0   \n",
      "678           0           0  ...           0       0     1            0   \n",
      "679           0           0  ...           0       0     1            0   \n",
      "680           0           0  ...           0       0     1            0   \n",
      "681           0           0  ...           0       0     1            0   \n",
      "682           0           0  ...           0       0     1            0   \n",
      "683           0           0  ...           0       0     1            0   \n",
      "684           0           0  ...           0       0     1            0   \n",
      "685           0           0  ...           0       0     1            0   \n",
      "686           0           0  ...           0       0     1            0   \n",
      "687           0           0  ...           0       0     1            0   \n",
      "688           0           0  ...           0       0     1            0   \n",
      "689           0           0  ...           0       0     1            0   \n",
      "690           0           0  ...           0       0     1            0   \n",
      "691           0           0  ...           0       0     1            0   \n",
      "692           0           0  ...           0       0     1            0   \n",
      "693           0           0  ...           0       0     1            0   \n",
      "694           0           0  ...           1       1     0            0   \n",
      "695           0           0  ...           1       1     0            0   \n",
      "696           0           0  ...           1       1     0            0   \n",
      "697           0           0  ...           1       1     0            0   \n",
      "698           0           0  ...           1       1     0            0   \n",
      "699           0           0  ...           1       1     0            0   \n",
      "700           0           0  ...           1       1     0            0   \n",
      "\n",
      "     Not Hisp/Latino  Black  White   AD   CN  LMCI  \n",
      "0                  1      0      1  0.1  1.0   0.1  \n",
      "1                  1      0      1  0.1  1.0   0.1  \n",
      "2                  1      0      1  0.1  1.0   0.1  \n",
      "3                  1      0      1  0.1  1.0   0.1  \n",
      "4                  1      0      1  0.1  1.0   0.1  \n",
      "5                  1      0      1  0.1  0.9   0.2  \n",
      "6                  1      0      1  0.1  1.0   0.1  \n",
      "7                  1      0      1  0.1  1.0   0.1  \n",
      "8                  1      0      1  1.0  0.1   0.1  \n",
      "9                  1      0      1  1.0  0.1   0.1  \n",
      "10                 1      0      1  1.0  0.1   0.1  \n",
      "11                 1      0      1  1.0  0.1   0.1  \n",
      "12                 1      0      1  1.0  0.1   0.1  \n",
      "13                 1      0      1  0.1  1.0   0.1  \n",
      "14                 1      0      1  0.1  1.0   0.1  \n",
      "15                 1      0      1  0.1  1.0   0.1  \n",
      "16                 1      0      1  0.1  1.0   0.1  \n",
      "17                 1      0      1  0.1  1.0   0.1  \n",
      "18                 1      0      1  0.1  0.1   1.0  \n",
      "19                 1      0      1  0.1  0.1   1.0  \n",
      "20                 1      0      1  0.1  0.1   1.0  \n",
      "21                 1      0      1  0.1  0.1   1.0  \n",
      "22                 1      0      1  0.1  0.1   1.0  \n",
      "23                 1      0      1  0.1  0.1   1.0  \n",
      "24                 1      0      1  0.1  0.1   1.0  \n",
      "25                 1      0      1  0.1  0.1   1.0  \n",
      "26                 1      0      1  0.1  0.1   1.0  \n",
      "27                 1      0      1  0.1  0.1   1.0  \n",
      "28                 1      0      1  0.1  0.1   1.0  \n",
      "29                 1      0      1  0.1  0.1   1.0  \n",
      "..               ...    ...    ...  ...  ...   ...  \n",
      "671                1      0      1  0.1  0.1   1.0  \n",
      "672                1      0      1  0.1  0.1   1.0  \n",
      "673                1      0      1  0.1  0.1   1.0  \n",
      "674                1      0      1  0.1  0.1   1.0  \n",
      "675                1      0      1  0.1  0.1   1.0  \n",
      "676                1      0      1  0.1  0.1   1.0  \n",
      "677                1      0      1  0.1  0.1   1.0  \n",
      "678                1      0      1  0.1  0.1   1.0  \n",
      "679                1      0      1  0.1  0.1   1.0  \n",
      "680                1      0      1  0.1  0.1   1.0  \n",
      "681                1      0      1  0.1  0.1   1.0  \n",
      "682                1      0      1  0.1  0.1   1.0  \n",
      "683                1      0      1  0.1  0.1   1.0  \n",
      "684                1      0      1  0.1  0.1   1.0  \n",
      "685                1      0      1  0.1  0.1   1.0  \n",
      "686                1      0      1  0.1  0.1   1.0  \n",
      "687                1      0      1  0.1  0.1   1.0  \n",
      "688                1      0      1  0.1  0.1   1.0  \n",
      "689                1      0      1  0.1  0.1   1.0  \n",
      "690                1      0      1  0.1  0.1   1.0  \n",
      "691                1      0      1  0.1  0.1   1.0  \n",
      "692                1      0      1  0.1  0.1   1.0  \n",
      "693                1      0      1  0.1  0.1   1.0  \n",
      "694                1      0      1  0.1  0.1   1.0  \n",
      "695                1      0      1  0.1  0.1   1.0  \n",
      "696                1      0      1  0.1  0.1   1.0  \n",
      "697                1      0      1  0.1  0.1   1.0  \n",
      "698                1      0      1  0.1  0.1   1.0  \n",
      "699                1      0      1  0.1  0.1   1.0  \n",
      "700                1      0      1  0.1  0.1   1.0  \n",
      "\n",
      "[697 rows x 165 columns]\n",
      "[1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2\n",
      " 2 2 2 2 2 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2\n",
      " 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 2 2 2 2 2 0 0\n",
      " 1 1 0 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 0\n",
      " 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 0 0 0 2 2\n",
      " 2 2 2 0 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2\n",
      " 2 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1\n",
      " 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 0 0 0 0 2 2 2 2 2 2 2 2 2 2 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 1 1 0 0 0 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 0 0 2 2 2 2 2 2 2 2 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "yproba=clf.predict_proba(X)\n",
    "\n",
    "binlab=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "bins=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "X['AD']=pd.cut(yproba[:,-3],bins,labels=binlab, include_lowest=True)\n",
    "X['CN']=pd.cut(yproba[:,-2],bins,labels=binlab, include_lowest=True)\n",
    "X['LMCI']=pd.cut(yproba[:,-1],bins,labels=binlab, include_lowest=True)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest + Probabilistic Dsitillation + Support Vector Machines**<br>\n",
    "For our Unique Model. We wish to carry out ensemble training. Random Forest Method itself taking the role of an ensemble training technique, we have implemented the use of probabilistc Distillation explained above. And using the new dataset, we carried out the Support Vector Mechanism to calculate our results. In this stage, we will divide the Dataset into training and test data. We will then apply the SupportVector Machine Classifier to the training input and targets. We will look at the efficiency of the algorithm on the Training data. Then we will use the algorithm to predict test data output to know the efficiency of our algoritm after which we will evaluate the model and obtain Mean Avg precision, recall and f1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest + Probabilistic Distillation + SVM  is: 97.12\n",
      "Accuracy of a Random Forest + Probabilistic Distillation + SVM predicted over actual is: 97.14\n",
      "The confusion Matrix is as Below:\n",
      "\n",
      "[[18  0  0]\n",
      " [ 0 43  4]\n",
      " [ 0  0 75]]\n",
      "\n",
      "The Evaluation Report is as Below:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       1.00      1.00      1.00        18\n",
      "          CN       1.00      0.91      0.96        47\n",
      "        LMCI       0.95      1.00      0.97        75\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       140\n",
      "   macro avg       0.98      0.97      0.98       140\n",
      "weighted avg       0.97      0.97      0.97       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train2,x_test2,y_train2,y_test2=train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "clf2 = svm.SVC(gamma=0.01, C=100.)\n",
    "clf2=clf2.fit(x_train2,y_train2)\n",
    "\n",
    "scores = cross_val_score(clf2, x_train2, y_train2, cv=5)\n",
    "print(\"Accuracy of Random Forest + Probabilistic Distillation + SVM  is:\",round(np.mean((scores*100)),2))\n",
    "\n",
    "yp2=clf2.predict(x_test2)\n",
    "print(\"Accuracy of a Random Forest + Probabilistic Distillation + SVM predicted over actual is:\",round(((accuracy_score(y_test2,yp2))*100),2))\n",
    "listt=list(le.classes_)\n",
    "y_test2=list(le.inverse_transform(y_test2))\n",
    "yp2=list(le.inverse_transform(yp2))\n",
    "#Evaluation\n",
    "print('The confusion Matrix is as Below:\\n')\n",
    "print(confusion_matrix(y_test2,yp2,labels=listt))\n",
    "print('\\nThe Evaluation Report is as Below:\\n')\n",
    "print(classification_report(y_test2,yp2,target_names=listt))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest + Probabilistic Dsitillation + K Nearest Neighbour**<br>\n",
    "For our Unique Model. We wish to carry out ensemble training. Random Forest Method itself taking the role of an ensemble training technique, we have implemented the use of probabilistc Distillation explained above. And using the new dataset, we carried out the K Nearest Neighbour Technique to calculate our results. In this stage, we will divide the Dataset into training and test data. We will then apply the Kk Nearest Neighbour Classifier to the training input and targets. We will look at the efficiency of the algorithm on the Training data. Then we will use the algorithm to predict test data output to know the efficiency of our algoritm after which we will evaluate the model and obtain Mean Avg precision, recall and f1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest + Probabilistic Distillation + 3KNN  is: 91.92\n",
      "Accuracy of a Random Forest + Probabilistic Distillation + 3KNN predicted over actual is: 42.14\n",
      "The confusion Matrix is as Below:\n",
      "\n",
      "[[ 6  5 15]\n",
      " [ 4 12 24]\n",
      " [10 23 41]]\n",
      "\n",
      "The Evaluation Report is as Below:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.30      0.23      0.26        26\n",
      "          CN       0.30      0.30      0.30        40\n",
      "        LMCI       0.51      0.55      0.53        74\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       140\n",
      "   macro avg       0.37      0.36      0.36       140\n",
      "weighted avg       0.41      0.42      0.42       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train3,x_test3,y_train3,y_test3=train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "clf3=KNeighborsClassifier(n_neighbors=3)\n",
    "clf3=clf3.fit(x_train3,y_train3)\n",
    "\n",
    "scores = cross_val_score(clf3, x_train3, y_train3, cv=5)\n",
    "print(\"Accuracy of Random Forest + Probabilistic Distillation + 3KNN  is:\",round(np.mean((scores*100)),2))\n",
    "\n",
    "yp3=clf3.predict(x_test2)\n",
    "print(\"Accuracy of a Random Forest + Probabilistic Distillation + 3KNN predicted over actual is:\",round(((accuracy_score(y_test3,yp3))*100),2))\n",
    "listt=list(le.classes_)\n",
    "y_test3=list(le.inverse_transform(y_test3))\n",
    "yp3=list(le.inverse_transform(yp3))\n",
    "#Evaluation\n",
    "print('The confusion Matrix is as Below:\\n')\n",
    "print(confusion_matrix(y_test3,yp3,labels=listt))\n",
    "print('\\nThe Evaluation Report is as Below:\\n')\n",
    "print(classification_report(y_test3,yp3,target_names=listt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
